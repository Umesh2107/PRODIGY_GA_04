# ğŸ§  Image-to-Image Translation with Pix2Pix (cGAN)

This project implements an image-to-image translation model using a **Conditional Generative Adversarial Network (cGAN)** called **Pix2Pix**. The model is trained on the [Facades dataset](https://www.tensorflow.org/datasets/catalog/cycle_gan#cycle_ganfan), which maps building edge sketches to photo-realistic buildings.

---

## âœ¨ Features

- âœ… Uses TensorFlow 2.x and TensorFlow Datasets (TFDS)
- âœ… Prepares and normalizes paired image data
- âœ… Implements Pix2Pix Generator (U-Net) and Discriminator (PatchGAN)
- âœ… Trains the model end-to-end
- âœ… Visualizes predictions after training
- âœ… Downloads generated images locally from Colab

---

## ğŸ“ Dataset

- **Name:** `cycle_gan/facades`
- **Type:** Paired image dataset
- **Source:** TensorFlow Datasets
- **Structure:**
  - `trainA`: input (edges)
  - `trainB`: target (photos)

---

## ğŸ› ï¸ Installation

No setup needed in Colab.

If running locally:

```bash
pip install tensorflow tensorflow-datasets matplotlib pillow
